{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers xmltodict accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForImageTextToText\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mychen76/invoice-and-receipts_donut_v1\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"mychen76/invoice-and-receipts_donut_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, transformers, accelerate, platform\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"transformers\", transformers.__version__)\n",
    "print(\"accelerate\", accelerate.__version__)\n",
    "print(\"python\", platform.python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "model_id = \"mychen76/invoice-and-receipts_donut_v1\"\n",
    "processor = DonutProcessor.from_pretrained(model_id)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,      # <-- single device â†’ no meta tensors\n",
    "    low_cpu_mem_usage=False,      # full, eager load\n",
    "    torch_dtype=torch.float32,    # or float16 if VRAM is tight\n",
    ")\n",
    "\n",
    "print(next(model.parameters()).device)    # cuda:0  (or cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def generateTextInImage(processor,model,input_image,task_prompt=\"<s_receipt>\"):\n",
    "    pixel_values = processor(input_image, return_tensors=\"pt\").pixel_values\n",
    "    print (\"input pixel_values: \",pixel_values.shape)\n",
    "    task_prompt = \"<s_receipt>\"\n",
    "    decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    outputs = model.generate(pixel_values.to(device),\n",
    "                               decoder_input_ids=decoder_input_ids.to(device),\n",
    "                               max_length=model.decoder.config.max_position_embeddings,\n",
    "                               early_stopping=True,\n",
    "                               pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                               eos_token_id=processor.tokenizer.eos_token_id,\n",
    "                               use_cache=True,\n",
    "                               num_beams=1,\n",
    "                               bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "                               return_dict_in_generate=True,\n",
    "                               output_scores=True,)\n",
    "    return outputs\n",
    "\n",
    "def generateOutputXML(processor,model, input_image, task_start=\"<s_receipt>\",task_end=\"</s_receipt>\"):\n",
    "    import re\n",
    "    outputs=generateTextInImage(processor,model,input_image,task_prompt=task_start)\n",
    "    sequence = processor.batch_decode(outputs.sequences)[0]\n",
    "    print(sequence)\n",
    "    sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # remove first task start token\n",
    "    return sequence\n",
    "\n",
    "def convertOutputToJson(processor, xml):\n",
    "    sequence = generateOutputXML()\n",
    "    result=processor.token2json(sequence)\n",
    "    print(\":vampire:\",result)\n",
    "    return result\n",
    "\n",
    "def generateOutputJson(processor,model, input_image, task_start=\"<s_receipt>\",task_end=\"</s_receipt>\"):\n",
    "    xml = generateOutputXML(processor,model, input_image,task_start=task_start,task_end=task_end)\n",
    "    result=processor.token2json(xml)\n",
    "    print(\":vampire:\",result)\n",
    "    return result\n",
    "\n",
    "IMAGE_PATH = \"./cropped_receipt/cropped_image.png\"\n",
    "OUTPUT_PATH = \"./outputs/hf_donut.json\"\n",
    "input_image = Image.open(IMAGE_PATH)\n",
    "\n",
    "## generate json\n",
    "invoice1_json=generateOutputJson(processor,model,input_image)\n",
    "print(invoice1_json)\n",
    "with open(OUTPUT_PATH, 'w') as file:\n",
    "    json.dump(invoice1_json, file, indent=4)\n",
    "\n",
    "\n",
    "# ## generate xml\n",
    "# xml=generateOutputXML(processor,model,input_image)\n",
    "# print(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
